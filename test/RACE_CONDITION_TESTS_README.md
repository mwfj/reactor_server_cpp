# Race Condition Test Suite

This document describes the comprehensive race condition test suite created to validate all fixes documented in [`EVENTFD_RACE_CONDITION_FIXES.md`](../EVENTFD_RACE_CONDITION_FIXES.md).

## Overview

The race condition test suite specifically targets multi-threaded edge cases and race conditions that were discovered and fixed during development. These tests ensure that the fixes remain effective and prevent regression.

## Test File

**Location**: [test/race_condition_test.h](race_condition_test.h)

## Test Coverage

### RC-TEST-1: Dispatcher Initialization (Issue 1)

**Validates**: EventFD implementation and two-phase initialization pattern

**What it tests**:
- Dispatcher can be created without crash
- `Init()` can be called after construction without `bad_weak_ptr` exception
- Event loop can start and stop cleanly
- wake_channel_ is properly initialized

**Related Issues**:
- Uninitialized `wake_channel_` dereferencing
- `shared_from_this()` called in constructor
- Resource leaks

---

### RC-TEST-2: EnQueue Deadlock Prevention (Issue 1.3)

**Validates**: Lock-free task execution in `HandleEventId()`

**What it tests**:
- Tasks can be enqueued without deadlock
- Concurrent connections trigger EnQueue internally
- No deadlock when tasks call EnQueue recursively
- Mutex is not held during task execution

**Related Issues**:
- Deadlock when task calls `EnQueue()` while mutex is held
- Poor concurrency from long mutex hold times

---

### RC-TEST-3: Double Close Prevention (Issue 2.1, 2.4)

**Validates**: Atomic close guards and duplicate callback prevention

**What it tests**:
- 50 rapid connect/disconnect cycles
- No "Bad file descriptor" errors from double-close
- No duplicate "Connection Closed" messages
- `is_channel_closed_` and `is_closing_` atomic flags work correctly

**Related Issues**:
- Double-close bug causing fd reuse issues
- Duplicate close callbacks from multiple code paths
- Non-atomic boolean flags in multi-threaded code

---

### RC-TEST-4: Concurrent Event Handling (Issue 2.3)

**Validates**: Priority-based event handling with EPOLLRDHUP + EPOLLIN

**What it tests**:
- 30 clients send data and close rapidly
- EPOLLRDHUP and EPOLLIN events handled correctly
- Close events take priority (early return prevents other event processing)
- No crashes from concurrent read/close events

**Related Issues**:
- EPOLLRDHUP + EPOLLIN concurrent event race
- else-if logic prevented both events from being processed
- Read events calling close while close callback also runs

---

### RC-TEST-5: channel_map_ Multi-Threaded Race (Issue 4 - CRITICAL)

**Validates**: Mutex-protected channel_map_ access and safe pointer handling

**What it tests**:
- 20 worker threads Ã— 10 connections each = 200 concurrent operations
- Rapid connection creation/destruction while event loop processes events
- No segfaults from null pointer dereference
- Validate-before-dereference pattern works correctly
- Mutex prevents concurrent map modification

**Related Issues**:
- **CRITICAL SEGFAULT**: `Channel::HandleEvent (this=0x0)`
- Raw pointer from `epoll_wait()` dereferenced without validation
- No mutex protecting `channel_map_`
- Data races between `WaitForEvent()` and `RemoveChannel()`

**This is the most important test** - it directly reproduces the segfault from the GDB trace.

---

### RC-TEST-6: TOCTOU Race in epoll_ctl (Issue 3)

**Validates**: Defense-in-depth checks in `EpollHandler::UpdateEvent()`

**What it tests**:
- 40 clients trigger write mode then close immediately
- Creates TOCTOU window between `is_channel_closed_` check and `epoll_ctl()` call
- No "Bad file descriptor" exceptions
- Graceful error handling (EBADF, ENOENT, EEXIST)

**Related Issues**:
- Time-Of-Check-Time-Of-Use race condition
- Channel closed between check and epoll_ctl
- `epoll_ctl ADD failed: Bad file descriptor` errors

---

### RC-TEST-7: Atomic Closed Flag (Issue 2.2)

**Validates**: `std::atomic<bool>` for `is_channel_closed_` and `is_closing_`

**What it tests**:
- 25 sequential rapid connect/send/close cycles
- Atomic compare-exchange prevents duplicate operations
- No race conditions from non-atomic bool operations

**Related Issues**:
- Non-atomic `bool is_channel_closed_` allowed race conditions
- Multiple threads could both pass the check and double-close
- Changed to `std::atomic<bool>` with `compare_exchange_strong()`

---

## Running the Tests

### Run All Tests (Including Race Condition Tests)

```bash
make clean && make
./run
```

This runs:
1. Basic functional tests (6 tests)
2. Stress tests (1 test - 100 concurrent clients)
3. **Race condition tests (7 tests)**

### Run Only Race Condition Tests

```bash
make test_race
```

Or manually:
```bash
g++ -std=c++11 -g -Wall -Iinclude -Ithread_pool/include \
    server/dispatcher.cc server/epoll_handler.cc server/channel.cc \
    server/socket_handler.cc server/acceptor.cc server/connection_handler.cc \
    server/net_server.cc server/buffer.cc \
    thread_pool/src/threadpool.cc thread_pool/src/threadtask.cc \
    server/reactor_server.cc test/test_framework.cc \
    test/test_race_condition.cc -lpthread -o run_race_test

./run_race_test
```

---

## Test Results

### Expected Output

```
======================================================================
RACE CONDITION TESTS (EVENTFD_RACE_CONDITION_FIXES.md)
======================================================================

[RC-TEST-1] Dispatcher Initialization (EventFD setup)...
[RC-TEST-1] PASS: Dispatcher initialized without crash

[RC-TEST-2] EnQueue Deadlock Prevention...
[RC-TEST-2] PASS: No deadlock, 10 tasks completed

[RC-TEST-3] Double Close Prevention...
[RC-TEST-3] PASS: 49/50 clean closes

[RC-TEST-4] Concurrent Event Handling (EPOLLRDHUP + EPOLLIN)...
[RC-TEST-4] PASS: 30/30 handled concurrent events

[RC-TEST-5] channel_map_ Multi-Threaded Race Condition...
[RC-TEST-5] PASS: No crash with 200 connections (85% success rate)
              Messages sent/received: 67

[RC-TEST-6] TOCTOU Race in epoll_ctl...
[RC-TEST-6] PASS: 40/40 completed without epoll_ctl errors

[RC-TEST-7] Atomic Closed Flag...
[RC-TEST-7] PASS: 25/25 handled with atomic protection

============================================================
TEST RESULTS SUMMARY
============================================================
[PASS] RC-1: Dispatcher Initialization
[PASS] RC-2: EnQueue No Deadlock
[PASS] RC-3: Double Close Prevention
[PASS] RC-4: Concurrent Event Handling
[PASS] RC-5: channel_map_ Race Condition
[PASS] RC-6: TOCTOU Race epoll_ctl
[PASS] RC-7: Atomic Closed Flag
------------------------------------------------------------
Total: 7 | Passed: 7 | Failed: 0
============================================================
```

---

## Test Parameters

| Test | Clients | Threads | Operation | Key Metric |
|------|---------|---------|-----------|------------|
| RC-1 | N/A | 1 | Init/Run/Stop | No crash |
| RC-2 | 10 | 10 | Concurrent EnQueue | No deadlock |
| RC-3 | 50 | 50 | Rapid close | No double-close |
| RC-4 | 30 | 30 | Send + rapid close | Concurrent events |
| RC-5 | 200 | 20 | Massive concurrency | **No segfault** |
| RC-6 | 40 | 40 | Write + close race | TOCTOU handling |
| RC-7 | 25 | Sequential | Atomic flags | No race |

---

## Success Criteria

### Critical Tests (Must Pass 100%)
- **RC-1**: Dispatcher Initialization - Must not crash
- **RC-5**: channel_map_ Race - **Must not segfault** (this was the critical bug)

### High Priority (Should Pass >90%)
- RC-2: EnQueue Deadlock - No timeout/deadlock
- RC-3: Double Close - >90% clean closes
- RC-4: Concurrent Events - >90% handled
- RC-6: TOCTOU Race - >90% no epoll errors
- RC-7: Atomic Flags - >90% success

### Note on Success Rates

Some tests may have <100% success rates under extreme load due to:
- Connection refused (too many simultaneous connections)
- Timing-dependent edge cases
- OS resource limits

**The key metric is NO CRASHES/SEGFAULTS**, not 100% connection success.

---

## Integration with Main Test Suite

The race condition tests are integrated into [test/run_test.cc](run_test.cc) and run automatically after the stress tests:

```cpp
// Run basic functional tests
BasicTests::RunAllTests();

// Run stress tests
StressTests::RunStressTests();

// Run race condition tests (validates EVENTFD_RACE_CONDITION_FIXES.md)
RaceConditionTests::RunRaceConditionTests();

// Print test summary
TestFramework::PrintResults();
```

---

## Debugging Failed Tests

If a race condition test fails:

1. **Check for segfaults**: Look for "Segmentation fault" or core dumps
2. **Check error messages**: "Bad file descriptor", "epoll_ctl failed", etc.
3. **Review related code**: See the "Related Issues" section for each test
4. **Run under valgrind**: Check for memory corruption
5. **Run with GDB**: Capture stack traces on crash

```bash
# Run with valgrind
valgrind --leak-check=full ./run_race_only

# Run with GDB
gdb ./run_race_only
(gdb) run
# If crash occurs:
(gdb) bt
(gdb) frame 2
(gdb) info locals
```

---

## Test Maintenance

These tests should be run:
- **Before each release** - Verify no regression
- **After any concurrency changes** - Especially in Dispatcher, EpollHandler, Channel
- **After modifying smart pointers** - Memory management changes can introduce races
- **When adding new features** - Ensure new code doesn't break existing race fixes

---

## References

- **Bug Documentation**: [EVENTFD_RACE_CONDITION_FIXES.md](../EVENTFD_RACE_CONDITION_FIXES.md)
- **Architecture**: [CLAUDE.md](../CLAUDE.md)
- **Test Framework**: [test_framework.h](test_framework.h)
- **Basic Tests**: [basic_test.h](basic_test.h)
- **Stress Tests**: [stress_test.h](stress_test.h)

---

## Version History

- **2025-10-27**: Initial creation - All 7 race condition tests passing
  - Validates all issues from EVENTFD_RACE_CONDITION_FIXES.md
  - Focus on Issue 4 (CRITICAL segfault) prevention
  - 100% test pass rate on initial run
